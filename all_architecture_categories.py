# Generated file with all architecture categories

ALL_ARCHITECTURE_CATEGORIES = [
    {'name': 'Перцептрон (Perceptron)', 'description': 'Простейшая модель искусственного нейрона, используемая для бинарной классификации.'},
    {'name': 'Adaline / Madaline', 'description': 'Адаптивный линейный элемент и его многослойное расширение, используемые для классификации и регрессии.'},
    {'name': 'Многослойный перцептрон (MLP, Multilayer Perceptron)', 'description': 'Нейронная сеть с прямой связью, состоящая из одного или нескольких скрытых слоев.'},
    {'name': 'Самоорганизующаяся карта Кохонена (SOM, Self-Organizing Map)', 'description': 'Тип нейронной сети, используемый для кластеризации и визуализации многомерных данных.'},
    {'name': 'Обучение векторному квантованию (LVQ, Learning Vector Quantization)', 'description': 'Метод машинного обучения для задач классификации, основанный на сопоставлении с образцами.'},
    {'name': 'Экстремальная машина обучения (ELM, Extreme Learning Machine)', 'description': 'Метод обучения однослойных нейронных сетей с быстрым обучением и хорошей обобщающей способностью.'},
    {'name': 'Нейронная сеть с радиальными базисными функциями (RBF Network)', 'description': 'Сеть с радиальными базисными функциями, используемая для аппроксимации функций и классификации.'},
    {'name': 'Вероятностная нейронная сеть (PNN, Probabilistic Neural Network)', 'description': 'Статистическая нейронная сеть, основанная на байесовской теории вероятностей.'},
    {'name': 'Глубокие порождающие модели (DBN, Deep Belief Network)', 'description': 'Глубокая нейронная сеть, состоящая из нескольких слоев стохастических скрытых переменных.'},
    {'name': 'Автоэнкодер (Autoencoder)', 'description': 'Нейронная сеть, обучаемая восстанавливать входные данные на выходе, обычно используется для снижения размерности.'},
    {'name': 'Деноизинговый автоэнкодер (DAE, Denoising Autoencoder)', 'description': 'Автоэнкодер, обучаемый восстанавливать чистые данные из зашумленных входов.'},
    {'name': 'Контрактивный автоэнкодер (CAE, Contractive Autoencoder)', 'description': 'Автоэнкодер, использующий контрактивный штраф для получения инвариантных представлений.'},
    {'name': 'Разреженный автоэнкодер (Sparse Autoencoder)', 'description': 'Автоэнкодер, использующий разреженность для ограничения активации нейронов в скрытом слое.'},
    {'name': 'Вариационный автоэнкодер (VAE, Variational Autoencoder)', 'description': 'Генеративная модель, объединяющая автоэнкодеры и вариационный вывод для генерации новых данных.'},
    {'name': 'Адверсариальный автоэнкодер (AAE, Adversarial Autoencoder)', 'description': 'Автоэнкодер, использующий состязательное обучение для формирования латентного пространства.'},
    {'name': 'Глубокая складывающаяся сеть (DSN, Deep Stacking Network)', 'description': 'Архитектура глубокого обучения, использующая модульную структуру с последовательным обучением слоев.'},
    {'name': 'Сети Колмогорова-Арнольда (KAN, Kolmogorov-Arnold Networks)', 'description': 'Нейронные сети, основанные на теореме Колмогорова-Арнольда о представлении непрерывных функций.'},
    {'name': 'Оптимизированные локальные KAN (X-KAN)', 'description': 'Модифицированная версия KAN с улучшенной локальной аппроксимацией функций.'},
    {'name': 'KAGNN (KAN for Graph Neural Networks)', 'description': 'Адаптация сетей Колмогорова-Арнольда для работы с графовыми структурами данных.'},
    {'name': 'Convolutional Architectures (CNN)', 'description': 'Neural network architectures primarily based on convolutional layers, commonly used for image processing and computer vision tasks.'},
    {'name': 'Efficient & Mobile Architectures', 'description': 'structured software design patterns (MVC, MVP, MVVM, MVI) that ensure high performance, ease of support, and scalability of applications.'},
    {'name': 'Energy & Equilibrium Architectures', 'description': 'analytical tools used to predict the state of complex systems (economic or physico-chemical) based on the balance of supply and demand, minimizing costs and optimizing the use of resources. They find the optimal balance by ensuring consistency between production capacity, commodity/energy flows, and consumption.'},
    {'name': 'Перцептрон (Perceptron)', 'description': 'Простейшая модель искусственного нейрона, используемая для бинарной классификации.'},
    {'name': 'Adaline / Madaline', 'description': 'Адаптивный линейный элемент и его многослойное расширение, используемые для классификации и регрессии.'},
    {'name': 'Многослойный перцептрон (MLP, Multilayer Perceptron)', 'description': 'Нейронная сеть с прямой связью, состоящая из одного или нескольких скрытых слоев.'},
    {'name': 'Самоорганизующаяся карта Кохонена (SOM, Self-Organizing Map)', 'description': 'Тип нейронной сети, используемый для кластеризации и визуализации многомерных данных.'},
    {'name': 'Обучение векторному квантованию (LVQ, Learning Vector Quantization)', 'description': 'Метод машинного обучения для задач классификации, основанный на сопоставлении с образцами.'},
    {'name': 'Экстремальная машина обучения (ELM, Extreme Learning Machine)', 'description': 'Метод обучения однослойных нейронных сетей с быстрым обучением и хорошей обобщающей способностью.'},
    {'name': 'Нейронная сеть с радиальными базисными функциями (RBF Network)', 'description': 'Сеть с радиальными базисными функциями, используемая для аппроксимации функций и классификации.'},
    {'name': 'Вероятностная нейронная сеть (PNN, Probabilistic Neural Network)', 'description': 'Статистическая нейронная сеть, основанная на байесовской теории вероятностей.'},
    {'name': 'Глубокие порождающие модели (DBN, Deep Belief Network)', 'description': 'Глубокая нейронная сеть, состоящая из нескольких слоев стохастических скрытых переменных.'},
    {'name': 'Автоэнкодер (Autoencoder)', 'description': 'Нейронная сеть, обучаемая восстанавливать входные данные на выходе, обычно используется для снижения размерности.'},
    {'name': 'Деноизинговый автоэнкодер (DAE, Denoising Autoencoder)', 'description': 'Автоэнкодер, обучаемый восстанавливать чистые данные из зашумленных входов.'},
    {'name': 'Контрактивный автоэнкодер (CAE, Contractive Autoencoder)', 'description': 'Автоэнкодер, использующий контрактивный штраф для получения инвариантных представлений.'},
    {'name': 'Разреженный автоэнкодер (Sparse Autoencoder)', 'description': 'Автоэнкодер, использующий разреженность для ограничения активации нейронов в скрытом слое.'},
    {'name': 'Вариационный автоэнкодер (VAE, Variational Autoencoder)', 'description': 'Генеративная модель, объединяющая автоэнкодеры и вариационный вывод для генерации новых данных.'},
    {'name': 'Адверсариальный автоэнкодер (AAE, Adversarial Autoencoder)', 'description': 'Автоэнкодер, использующий состязательное обучение для формирования латентного пространства.'},
    {'name': 'Глубокая складывающаяся сеть (DSN, Deep Stacking Network)', 'description': 'Архитектура глубокого обучения, использующая модульную структуру с последовательным обучением слоев.'},
    {'name': 'Сети Колмогорова-Арнольда (KAN, Kolmogorov-Arnold Networks)', 'description': 'Нейронные сети, основанные на теореме Колмогорова-Арнольда о представлении непрерывных функций.'},
    {'name': 'Оптимизированные локальные KAN (X-KAN)', 'description': 'Модифицированная версия KAN с улучшенной локальной аппроксимацией функций.'},
    {'name': 'KAGNN (KAN for Graph Neural Networks)', 'description': 'Адаптация сетей Колмогорова-Арнольда для работы с графовыми структурами данных.'},
    {'name': 'FeedForward Architectures', 'description': 'artificial neural networks in which the signal propagates strictly from the input layer to the output'},
    {'name': 'Graph Neural Networks (GNN)', 'description': 'Neural networks specifically designed to operate on graph-structured data, processing relationships between entities.'},
    {'name': 'Generative Architectures', 'description': 'A type of machine learning algorithms and neural networks designed to create new, original content (text, images, sound, video, code) that mimics the structure and style of training data'},
    {'name': 'Мультимодальные архитектуры', 'description': 'Архитектуры, способные обрабатывать несколько различных типов данных одновременно.'},
    {'name': 'Архитектуры для поиска архитектур (NAS)', 'description': 'Архитектуры, используемые для автоматического поиска оптимальных архитектур нейронных сетей.'},
    {'name': 'NeuralODEs&Continuous', 'description': 'They allow simulating the continuous change of latent states, which opens up new possibilities for time series analysis, signal processing, and dynamic systems'},
    {'name': 'Neuro-Symbolic&Hybrid Architectures', 'description': 'architectures where learnability (the ability to extract knowledge from experience) is combined with determinism (the ability to follow strict rules)'},
    {'name': 'Архитектуры для обучения с усилением (RL)', 'description': 'Архитектуры, разработанные специально для задач обучения с подкреплением.'},
    {'name': 'Recurant&Sequental Architectures', 'description': 'These are architectures that perceive the world not as a set of frozen frames, but as a continuous stream, where the past determines the understanding of the present'},
    {'name': 'Архитектуры для малых данных и FEW-SHOT LEARNING', 'description': 'Models are able to draw accurate conclusions based on an extremely limited set of examples (literally 1-5 samples), simulating the human ability to learn quickly.'},
    {'name': 'Специализированные архитектуры', 'description': 'Архитектуры, разработанные для конкретных задач или областей применения.'},
    {'name': 'Spike and neuromorphic architectures', 'description': 'simulations of the biological principles of the brain at the hardware and software levels to achieve extreme energy efficiency and real-time operation'},
    {'name': 'State Space Models and Post-Transformer Architectures', 'description': 'Modern architectures including state space models and other approaches that emerged after transformer dominance.'},
    {'name': 'Transformers and mechanisms of attention', 'description': 'abandoning sequential data processing in favor of parallelism and the ability of the model to instantly determine the significance of relationships between any data elements, regardless of the distance between them.'},
]
